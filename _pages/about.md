---
permalink: /
title: "Curtis McDonald Personal Webpage"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

# About

I am currently a 4th year PhD Student in the Statistics and Data Science Department at Yale University. I work with my advisor Andrew Barron on topics related to sampling problems, greedy optimization of neural networks, and Markov Chain Monte Carlo (MCMC).

The main theme of my research from my Master’s education into my PhD has been the convergence behaviour of stochastic processes. In my initial research, this focused on filter stability for Hidden Markov Models (HMM) and applications to robust stochastic control. Namely, given a bad prior can an agent still learn an accurate posterior on the hidden state of the system and then use this to make good control decisions.

More recently, I am interested in mixing time guarantees of sampling approaches for multi modal and non-log concave target densities. What methods are most effective to produce samples from such difficult densities? Traditional MCMC methods can have difficulty exploring the full state space and can get trapped in local modes of the log likelihood. Time varying transition rules, annealing, optimal transport, and score-based methods all present interesting alternatives to produce samples for such densities beyond traditional MCMC.

I received my undergraduate degree in Applied Mathematics and Engineering from Queen’s University in 2017. I also received my Master’s in Applied Science, specializing in Mathematics and Engineering, from Queen’s University in 2019. In 2019 I moved to New Haven, CT where I am currently pursuing my PhD at Yale University. 

For more information, please see my [Publications](https://cmcdonald-1.github.io/publications/) page, [CV](https://cmcdonald-1.github.io/assets/pdf/CV_2022.pdf), or [LinkedIN](https://www.linkedin.com/in/curtis-mcdonald-010a63254/) profile.

# Upcoming News

* I will be presenting a poster at the Score Based Methods Workshop at NeurIPS 2022 in December titled *"Proposal of a Score Based Approach to Sampling Using Monte Carlo Estimation of Score and Oracle Access to Target Density"*. This work represents an extension on score based methods from generative modeling to posterior sampling.

* In the upcoming summer of 2023, I am interested in working on a summer internship with a technology company revolving around sampling problems, generative models, or stochastic processes and deep networks. If you would like to contact me, please reach out at curtis.mcdonald@yale.edu.



